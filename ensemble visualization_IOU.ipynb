{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code computes the class relevance maps for individual images through different base learners and performs an ensemble of the localized ROI, computes the IOU with the ground truth and finally measures the mean average precision across different IOU thresholds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading libraries\n",
    "from __future__ import print_function\n",
    "\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.inception_resnet_v2 import InceptionResNetV2\n",
    "from keras.models import Sequential, Model, Input, load_model\n",
    "from keras.layers import Conv2D, Dense, MaxPooling2D, SeparableConv2D, BatchNormalization, ZeroPadding2D, Flatten,Average, BatchNormalization, Dropout\n",
    "from keras.layers import GlobalAveragePooling2D, GlobalMaxPooling2D\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.models import *\n",
    "import keras.backend as K\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "\n",
    "from scipy import ndimage\n",
    "from skimage.measure import regionprops\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from PIL import Image\n",
    "\n",
    "import numpy as np\n",
    "import math\n",
    "import cv2\n",
    "import os\n",
    "import glob\n",
    "import h5py\n",
    "import csv\n",
    "import json\n",
    "\n",
    "from collections import namedtuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#custom definition functions to create JSON files for computing mean average precision\n",
    "\n",
    "# create json format\n",
    "def serializeGT(ImgName, g_coords):\n",
    "    return {ImgName:  g_coords,}\n",
    "\n",
    "def serializeCRM(ImgName, b_coords, b_scores):\n",
    "    return {ImgName: { \n",
    "            'boxes': b_coords,\n",
    "            'scores': b_scores,}\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#computing IOU\n",
    "def bb_intersection_over_union(boxA, boxB):\n",
    "# determine the (x, y)-coordinates of the intersection rectangle\n",
    "    xA = max(boxA[0], boxB[0])\n",
    "    yA = max(boxA[1], boxB[1])\n",
    "    xB = min(boxA[2], boxB[2])\n",
    "    yB = min(boxA[3], boxB[3])\n",
    " \n",
    "    # compute the area of intersection rectangle\n",
    "    interArea = max(0, xB - xA + 1) * max(0, yB - yA + 1)\n",
    " \n",
    "    # compute the area of both the prediction and ground-truth\n",
    "    # rectangles\n",
    "    boxAArea = (boxA[2] - boxA[0] + 1) * (boxA[3] - boxA[1] + 1)\n",
    "    boxBArea = (boxB[2] - boxB[0] + 1) * (boxB[3] - boxB[1] + 1)\n",
    " \n",
    "    # compute the intersection over union by taking the intersection\n",
    "    # area and dividing it by the sum of prediction + ground-truth\n",
    "    # areas - the interesection area\n",
    "    iou = interArea / float(boxAArea + boxBArea - interArea)\n",
    " \n",
    "    # return the intersection over union value\n",
    "    return iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the output layer of the individual base-nearners\n",
    "\n",
    "def get_output_layer(model, layer_name):\n",
    "    try:\n",
    "        # get the symbolic outputs of each \"key\" layer (we gave them unique names).\n",
    "        layer_dict = dict([(layer.name, layer) for layer in model.layers])\n",
    "        layer = layer_dict[layer_name]\n",
    "        return layer\n",
    "    except Exception as e:\n",
    "        raise Exception('Error from get_output_layer(): ' + str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to generate the CRM bounding box for a given CRM threshold\n",
    "def generate_BoundingBox(aCRM, threshold):\n",
    "    try:\n",
    "        labeled_CRM, nr_objects = ndimage.label(aCRM > threshold)\n",
    "        props = regionprops(labeled_CRM)\n",
    "        return props\n",
    "    except Exception as e:\n",
    "        raise Exception('Error from generate_BoundingBox(): ' + str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confidence score = highest heatmap value in box * classification score\n",
    "def Calculate_Confidence_Score(aCRM, bboxes, outScores):\n",
    "    try:\n",
    "        c_scores = []\n",
    "        for a_b in bboxes:\n",
    "            a_bbox = aCRM[a_b[1]:a_b[3], a_b[0]:a_b[2]]       \n",
    "            a_score = np.max(a_bbox)\n",
    "            b_score = outScores[0][0]\n",
    "            c_scores.append(np.max(a_bbox) * outScores[0][0])\n",
    "        \n",
    "        return np.array(c_scores)\n",
    "        \n",
    "    except Exception as e:\n",
    "        raise Exception('Error from Calculate_Confidence_Score(): ' + str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to compute the CRM\n",
    "\n",
    "def Generate_CRM_2Class(thisModel, thisImg_path, Threshold):             \n",
    "    try:\n",
    "        # preprocess input image      \n",
    "        width, height = thisModel.input.shape[1:3].as_list()\n",
    "        original_img = cv2.imread(thisImg_path) \n",
    "        resized_original_image = cv2.resize(original_img, (width,height))        \n",
    "    \n",
    "        input_image = img_to_array(resized_original_image)\n",
    "        input_image = np.array(input_image, dtype=\"float\") /255.0       \n",
    "        input_image = input_image.reshape((1,) + input_image.shape)\n",
    "    \n",
    "        class_weights = thisModel.layers[-1].get_weights()[0]\n",
    "    \n",
    "        get_output = K.function([thisModel.layers[0].input], [thisModel.layers[-4].output, thisModel.layers[-1].output])\n",
    "        [conv_outputs, predictions] = get_output([input_image])\n",
    "        conv_outputs = conv_outputs[0, :, :, :]     \n",
    "        final_output = predictions   \n",
    "        \n",
    "        wf0 = np.zeros(dtype = np.float32, shape = conv_outputs.shape[0:2])    \n",
    "        wf1 = np.zeros(dtype = np.float32, shape = conv_outputs.shape[0:2])    \n",
    "    \n",
    "        for i, w in enumerate(class_weights[:, 0]):     \n",
    "            wf0 += w * conv_outputs[:, :, i]           \n",
    "        S0 = np.sum(wf0)           # score at node 0 in the final output layer\n",
    "        for i, w in enumerate(class_weights[:, 1]):     \n",
    "            wf1 += w * conv_outputs[:, :, i]             \n",
    "        S1 = np.sum(wf1)           # score at node 1 in the final output layer\n",
    "    \n",
    "        #Calculate incremental MSE\n",
    "        iMSE0 = np.zeros(dtype = np.float32, shape = conv_outputs.shape[0:2])\n",
    "        iMSE1 = np.zeros(dtype = np.float32, shape = conv_outputs.shape[0:2])\n",
    "    \n",
    "        row, col = wf0.shape\n",
    "        for x in range (row):\n",
    "                for y in range (col):\n",
    "                        tmp0 = np.array(wf0)\n",
    "                        tmp0[x,y] = 0.                   # remove activation at the spatial location (x,y)\n",
    "                        iMSE0[x,y] = (S0 - np.sum(tmp0)) ** 2\n",
    "    \n",
    "                        tmp1 = np.array(wf1)\n",
    "                        tmp1[x,y] = 0.                  \n",
    "                        iMSE1[x,y] = (S1 - np.sum(tmp1)) ** 2\n",
    "         \n",
    "      \n",
    "        Final_crm = iMSE0 + iMSE1                         # consider both positive and negative contribution\n",
    "    \n",
    "        Final_crm /= np.max(Final_crm)                                  # normalize\n",
    "        resized_Final_crm = cv2.resize(Final_crm, (height, width))      # upscaling to original image size\n",
    "\n",
    "        The_CRM = np.array(resized_Final_crm)\n",
    "        The_CRM[np.where(resized_Final_crm < Threshold)] = 0.           # clean-up (remove data below threshold)\n",
    "\n",
    "        return[resized_original_image, final_output, resized_Final_crm, The_CRM]\n",
    "    except Exception as e:\n",
    "        raise Exception('Error from Generate_CRM_2Class(): ' + str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#genrate bounding boxes\n",
    "def generate_bBox(thisCAM_img, Threshold):             \n",
    "    try:\n",
    "        bboxes = []\n",
    "        TheProps = generate_BoundingBox(thisCAM_img, Threshold)\n",
    "        for b in TheProps:\n",
    "            bbox = b.bbox\n",
    "            xs = bbox[1]\n",
    "            ys = bbox[0]\n",
    "            w = bbox[3] - bbox[1]\n",
    "            h = bbox[2] - bbox[0]\n",
    "\n",
    "            bboxes.append([bbox[1], bbox[0], bbox[3], bbox[2]])         \n",
    "\n",
    "        CRM_bboxes = np.vstack(bboxes)\n",
    "        \n",
    "        return CRM_bboxes\n",
    "\n",
    "    except Exception as e:\n",
    "        raise Exception('Error from generate_bBox(): ' + str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate IOU of the ground truth and precited boudning box\n",
    "def calculate_IOU (GT_bbox, a_bbox):\n",
    "    try:\n",
    "        iou = 0.\n",
    "        for c_b in a_bbox:\n",
    "            for g_b in GT_bbox:\n",
    "                iou += bb_intersection_over_union(g_b, c_b)\n",
    "        iou /= float(GT_bbox.shape[0])           # get average \n",
    "\n",
    "        return iou\n",
    "\n",
    "    except Exception as e:\n",
    "        raise Exception('Error from calculate_IOU(): ' + str(e))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the model and change the layer names of the VGG16 model in the ensemble to avoid similar name issues\n",
    "\n",
    "def VGG16_DL(model_input, num_classes):\n",
    "    try:\n",
    "        vgg16_cnn = VGG16(weights='imagenet', include_top=False, input_tensor=model_input)\n",
    "        vgg16_cnn = Model(inputs=vgg16_cnn.input, outputs=vgg16_cnn.get_layer('block5_conv3').output)\n",
    "        x = vgg16_cnn.output\n",
    "        x = GlobalAveragePooling2D()(x)\n",
    "        x = Dropout(0.5)(x)\n",
    "        predictions = Dense(num_classes, activation='softmax')(x)\n",
    "        model = Model(inputs=vgg16_cnn.input, outputs=predictions, name='vgg16_custom')\n",
    "        model.get_layer(name='block1_conv1').name='block1_conv1VGG'  \n",
    "        model.get_layer(name='block1_conv2').name='block1_conv2VGG' \n",
    "        model.get_layer(name='block2_conv1').name='block2_conv1VGG' \n",
    "        model.get_layer(name='block2_conv2').name='block2_conv2VGG' \n",
    "        model.get_layer(name='block3_conv1').name='block3_conv1VGG' \n",
    "        model.get_layer(name='block3_conv2').name='block3_conv2VGG' \n",
    "        model.get_layer(name='block3_conv3').name='block3_conv3VGG' \n",
    "        model.get_layer(name='block4_conv1').name='block4_conv1VGG' \n",
    "        model.get_layer(name='block4_conv2').name='block4_conv2VGG' \n",
    "        model.get_layer(name='block4_conv3').name='block4_conv3VGG' \n",
    "        model.get_layer(name='block5_conv1').name='block5_conv1VGG' \n",
    "        model.get_layer(name='block5_conv2').name='block5_conv2VGG' \n",
    "        model.get_layer(name='block5_conv3').name='block5_conv3VGG' \n",
    "        model.get_layer(name='block1_pool').name='block1_poolVGG' \n",
    "        model.get_layer(name='block2_pool').name='block2_poolVGG' \n",
    "        model.get_layer(name='block3_pool').name='block3_poolVGG' \n",
    "        model.get_layer(name='block4_pool').name='block4_poolVGG' \n",
    "        return model\n",
    "    except Exception as e:\n",
    "        raise Exception('Error from VGG16_DL(): ' + str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load models and compute CRM and create JSON files\n",
    "\n",
    "def Load_Pretrained_Model(thisModel_path, thisModel_name):\n",
    "    try:\n",
    "        # load weights into new model\n",
    "        loaded_model = load_model(os.path.join(thisModel_path, thisModel_name + '.h5'))\n",
    "        return(loaded_model)\n",
    "    except Exception as e:\n",
    "        raise Exception('Error from Load_Pretrained_Model(): ' + str(e))\n",
    "try:\n",
    "    # Load Keras model\n",
    "    print(\"Loading a total of 5 DL models...\") #ensemble of five base-learners\n",
    "    try:\n",
    "        img_width, img_height = 256, 256 #input dimensions\n",
    "        input_shape = (img_width, img_height, 3)\n",
    "        model_input = Input(shape=input_shape)\n",
    "        print(model_input)\n",
    "\n",
    "        try:\n",
    "            print(\"1) Loading VGG16-based model...\") #VGG16\n",
    "            VGG16_M = VGG16_DL(model_input, 2)\n",
    "            VGG16_M.load_weights(os.path.join('C:/Users/rajaramans2/codes/omsakthi_ensemble_visualization_kaggle/corase models and codes/with lung segmented chexpert/top-7_finetuned_models', 'vgg16_abnormality with coarse model.10-0.8923' + '.h5'))\n",
    "        except Exception as e:\n",
    "            raise Exception('Error in loading VGG16-based model: ' + str(e))\n",
    "\n",
    "        try:\n",
    "            print(\"3) Loading nasnet-based model...\") #NASNET\n",
    "            nasnet_M = Load_Pretrained_Model('C:/Users/rajaramans2/codes/omsakthi_ensemble_visualization_kaggle/corase models and codes/with lung segmented chexpert/top-7_finetuned_models', 'nasnet_abnormality_with coarse model.04-0.8734')\n",
    "        except Exception as e:\n",
    "            raise Exception('Error in loading nasnet-based model: ' + str(e))\n",
    "        \n",
    "        try:\n",
    "            print(\"4) Loading xception-based model...\") #Xception\n",
    "            xception_M = Load_Pretrained_Model('C:/Users/rajaramans2/codes/omsakthi_ensemble_visualization_kaggle/corase models and codes/with lung segmented chexpert/top-7_finetuned_models', 'xception_abnormality_with coarse model.12-0.8765')\n",
    "        except Exception as e:\n",
    "            raise Exception('Error in loading xception-based model: ' + str(e))\n",
    "\n",
    "        try:\n",
    "            print(\"5) Loading InceptionV3-based model...\") #InceptionV-3\n",
    "            InceptionV3_M = Load_Pretrained_Model('C:/Users/rajaramans2/codes/omsakthi_ensemble_visualization_kaggle/corase models and codes/with lung segmented chexpert/top-7_finetuned_models', 'inceptionv3_abnormality_with coarse model.03-0.8825')\n",
    "        except Exception as e:\n",
    "            raise Exception('Error in loading InceptionV3-based model: ' + str(e))\n",
    "\n",
    "        try:\n",
    "            print(\"6) Loading mobile-based model...\") #MobileNet\n",
    "            mobile_M = Load_Pretrained_Model('C:/Users/rajaramans2/codes/omsakthi_ensemble_visualization_kaggle/corase models and codes/with lung segmented chexpert/top-7_finetuned_models', 'mobile_abnormality_with coarse model.07-0.8799')\n",
    "        except Exception as e:\n",
    "            raise Exception('Error in loading mobile-based model: ' + str(e))\n",
    "\n",
    "    except Exception as e:\n",
    "        raise Exception('Error in loading CNN models: ' + str(e))\n",
    "  \n",
    "    try: #folder where the abnromal test data is stored in the PNG format\n",
    "        TestFolder_path = 'C:/Users/rajaramans2/codes/omsakthi_ensemble_visualization_kaggle/fine_data_kaggle/abnormality_classifier_binary/cropped/abnormality_aug/test/abnormal/'\n",
    "        print(\"Input image folder: \" + TestFolder_path)\n",
    "        Test_image_path = TestFolder_path + '*.png'\n",
    "        Test_image_Set = glob.glob(Test_image_path)\n",
    "    except Exception as e:\n",
    "        raise Exception('Error in retrieving images from dataset folder: ' + str(e))\n",
    "    \n",
    "    # Set-up output folders\n",
    "    try:\n",
    "        Visualization_path   = 'C:/Users/rajaramans2/codes/omsakthi_ensemble_visualization_kaggle/visualization/'\n",
    "        \n",
    "        #create folders to store the results of CRM and corresponding bounding box computations\n",
    "        #here we compute CRMs with no threshold and with different thresholds (0.1 to 0.8)\n",
    "        #we see which CRM threshold gives the best values for IOU computation\n",
    "        aCRM_output_path      = Visualization_path + 'aCRM'       \n",
    "        aCRM_bbox_output_path = Visualization_path + 'aCRM_bbox'        \n",
    "        tCRM_output_path      = Visualization_path + 'tCRM'      \n",
    "        tCRM_bbox_output_path = Visualization_path + 'tCRM_bbox'\n",
    "        \n",
    "        #file that stores the classification results and IOU computation\n",
    "        f1 = open(os.path.join(Visualization_path, 'y_ClassificationResult.txt'), 'w')\n",
    "\n",
    "        print(\"CRM output folder: \" + Visualization_path)\n",
    "    except Exception as e:\n",
    "        raise Exception('Error in setting up output folders: ' + str(e))\n",
    "\n",
    "    # Load groundtruth information from csv file\n",
    "    try:\n",
    "        cf = open('C:/Users/rajaramans2/codes/omsakthi_ensemble_visualization_kaggle/bounding_box_rsna_256.csv', 'r')\n",
    "    except Exception as e:\n",
    "        raise Exception('Error in loading csv file: ' + str(e))\n",
    "\n",
    "    #CRM thresholds\n",
    "    Th_set = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8]\n",
    "\n",
    "    avg_aIOU = np.zeros(len(Th_set))       \n",
    "    avg_tIOU = np.zeros(len(Th_set))       \n",
    "\n",
    "    bb_data = [dict() for x in range(len(Th_set))]\n",
    "    tb_data = [dict() for x in range(len(Th_set))]\n",
    "    gt_data = [dict() for x in range(len(Th_set))]\n",
    "\n",
    "    i = 0\n",
    "    err_cnt = 0\n",
    "    for Img_filename in Test_image_Set:\n",
    "\n",
    "        fname = os.path.basename(Img_filename)\n",
    "        name_only, ext_only = os.path.splitext(fname)\n",
    "\n",
    "        aCRM_ImgFile    = name_only           # for saving CRM heatmap image\n",
    "        aBbox_file      = name_only           # for saving bbox image\n",
    "\n",
    "        tCRM_ImgFile    = name_only           # for saving tCRM heatmap image\n",
    "        tBbox_file      = name_only           # for saving bbox image\n",
    "\n",
    "        # Check if a given test image has a ground-truth information (bbox) in the csv file. if not, skip the remaining process\n",
    "        bbox_set = []\n",
    "        FileFound = False\n",
    "        BBoxFound = False\n",
    "        k = 0\n",
    "        cf.seek(0)\n",
    "        CSVreader = csv.DictReader(cf)        \n",
    "        for row in CSVreader:           # 'for loop' for dealing with the case that a given image has multiple bounding boxes (actually very common)\n",
    "            if fname in row['patientId']:\n",
    "                FileFound = True        # OK found image file name in the CSV, next check if it has ground-truth bbox info.\n",
    "\n",
    "                if row['x_dis'] and row['y_dis'] and row['width_dis'] and row['height_dis']:\n",
    "                    bbox_set.append([int(row['x_dis']), int(row['y_dis']), int(row['x_dis'])+int(row['width_dis']), int(row['y_dis'])+int(row['height_dis'])])\n",
    "                    BBoxFound = True\n",
    "                    continue            # continue 'for loop' to see if this image has multiple bboxes\n",
    "                else:\n",
    "                    break\n",
    "            k += 1\n",
    "\n",
    "                                  \n",
    "        if FileFound:\n",
    "            if BBoxFound:\n",
    "                print('[' + str(i) + '] ' + fname + ': Found from ' + str(k) + 'th row in the dictionary')\n",
    "            else:\n",
    "                print('[' + str(i) + '] ' + fname + ': Found from ' + str(k) + 'th row in the dictionary (BBox info missing)')\n",
    "                continue                                # we only care about the image having groundtrugh bbox information\n",
    "        else:\n",
    "            print('[' + str(i) + '] ' + fname + ': Not Found from the dictionary')\n",
    "            continue\n",
    "\n",
    "        groundtruth_bbox_set = np.vstack(bbox_set)      # a list of ground-truth bbox information\n",
    "        \n",
    "\n",
    "        # Generate CRM based on the given DL model (aCRM: CRM as is, tCRM: CRM with thresholding)\n",
    "        InImage1, OutScores1, aCRM_Img1, tCRM_Img1 = Generate_CRM_2Class(VGG16_M,             Img_filename, 0.1) #CRM threshold is set to 0.1 here\n",
    "        InImage3, OutScores3, aCRM_Img3, tCRM_Img3 = Generate_CRM_2Class(nasnet_M,            Img_filename, 0.1)\n",
    "        InImage4, OutScores4, aCRM_Img4, tCRM_Img4 = Generate_CRM_2Class(xception_M,          Img_filename, 0.1)\n",
    "        InImage5, OutScores5, aCRM_Img5, tCRM_Img5 = Generate_CRM_2Class(InceptionV3_M,       Img_filename, 0.1)\n",
    "        InImage6, OutScores6, aCRM_Img6, tCRM_Img6 = Generate_CRM_2Class(mobile_M,            Img_filename, 0.1)\n",
    "\n",
    "        OutScores_F = (OutScores1 + OutScores3 + OutScores4 + OutScores5 + OutScores6)/5.0 #score normalization\n",
    "\n",
    "        eval_result = \"{}:    [{:.3f},  {:.3f}]\".format(fname, OutScores_F[0][0], OutScores_F[0][1])\n",
    "\n",
    "        target = OutScores_F[0][0]\n",
    "        TP = True                                                                                                                            \n",
    "        for other_output in OutScores_F[0]:\n",
    "            if target < other_output:\n",
    "                TP = False\n",
    "                break\n",
    "                    \n",
    "        if TP:          \n",
    "            aCRM_ImgFile += \"_aCRM.png\"\n",
    "            aBbox_file += \"_aBbox.png\"\n",
    "\n",
    "            tCRM_ImgFile += \"_tCRM.png\"\n",
    "            tBbox_file  += \"_tBbox.png\"\n",
    "            eval_result += \"      | \"\n",
    "        else:\n",
    "            err_cnt += 1\n",
    "\n",
    "            aCRM_ImgFile += \"_aCRM_err.png\"\n",
    "            aBbox_file += \"_aBbox_err.png\"\n",
    "\n",
    "            tCRM_ImgFile += \"_tCRM_err.png\"\n",
    "            tBbox_file  += \"_tBbox_err.png\"\n",
    "            eval_result += \"  ERR\\n\"           \n",
    "\n",
    "        # CRM image (does NOT apply thresholding to each individual CRM image)\n",
    "        aCRM_Img_F = aCRM_Img1 + aCRM_Img3 + aCRM_Img4 + aCRM_Img5 + aCRM_Img6 \n",
    "        aCRM_Img_F /= np.max(aCRM_Img_F)\n",
    "        \n",
    "        # CRM image (remove the area lower than a given threshold)\n",
    "        tCRM_Img_F = tCRM_Img1 + tCRM_Img3 + tCRM_Img4 + tCRM_Img5 + tCRM_Img6\n",
    "        tCRM_Img_F /= np.max(tCRM_Img_F)\n",
    "        \n",
    "        \n",
    "        for idx in range(len(Th_set)):\n",
    "        \n",
    "            aBBox_coord = generate_bBox(aCRM_Img_F, Th_set[idx])\n",
    "            aBBox_score = Calculate_Confidence_Score(aCRM_Img_F, aBBox_coord, OutScores_F)\n",
    "\n",
    "            aHeatmap = cv2.applyColorMap(np.uint8(255*aCRM_Img_F), cv2.COLORMAP_JET)\n",
    "            aHeatmap[np.where(aCRM_Img_F < Th_set[idx])] = 0            \n",
    "            aImg = np.float32(aHeatmap) + np.float32(InImage1)          \n",
    "            aImg = 255 * aImg / np.max(aImg)\n",
    "\n",
    "\n",
    "            tBBox_coord = generate_bBox(tCRM_Img_F, Th_set[idx])\n",
    "            tBBox_score = Calculate_Confidence_Score(tCRM_Img_F, tBBox_coord, OutScores_F)\n",
    "\n",
    "            tHeatmap = cv2.applyColorMap(np.uint8(255*tCRM_Img_F), cv2.COLORMAP_JET)\n",
    "            tHeatmap[np.where(tCRM_Img_F < Th_set[idx])] = 0            \n",
    "            tImg = np.float32(tHeatmap) + np.float32(InImage1)          \n",
    "            tImg = 255 * tImg / np.max(tImg)\n",
    "\n",
    "           \n",
    "            a_path      = aCRM_output_path + str(Th_set[idx]) + '/'\n",
    "            if not os.path.exists(a_path):\n",
    "                os.makedirs(a_path)              \n",
    "            cv2.imwrite(os.path.join(a_path, aCRM_ImgFile), aImg)\n",
    "\n",
    "            t_path      = tCRM_output_path + str(Th_set[idx]) + '/'\n",
    "            if not os.path.exists(t_path):\n",
    "                os.makedirs(t_path)              \n",
    "            cv2.imwrite(os.path.join(t_path, tCRM_ImgFile), tImg)\n",
    "\n",
    "            aIOU = calculate_IOU (groundtruth_bbox_set, aBBox_coord)\n",
    "            tIOU = calculate_IOU (groundtruth_bbox_set, tBBox_coord)\n",
    "            eval_result += \"aIOU_\" + str(Th_set[idx]) + \":  {:.4f} | \".format (aIOU)\n",
    "            eval_result += \"tIOU_\" + str(Th_set[idx]) + \":  {:.4f} | \".format (tIOU)\n",
    " \n",
    "            avg_aIOU[idx] += aIOU        \n",
    "            avg_tIOU[idx] += tIOU        \n",
    "\n",
    "            aOutImage = np.copy(aImg)\n",
    "            for c_b in aBBox_coord:\n",
    "                cv2.rectangle(aOutImage, (c_b[0], c_b[1]), (c_b[2], c_b[3]), (255,0,0), 2)\n",
    "            for g_b in groundtruth_bbox_set:\n",
    "                cv2.rectangle(aOutImage, (g_b[0], g_b[1]), (g_b[2], g_b[3]), (0,255,0), 2)\n",
    "\n",
    "            ab_path      = aCRM_bbox_output_path + str(Th_set[idx]) + '/'\n",
    "            if not os.path.exists(ab_path):\n",
    "                os.makedirs(ab_path)              \n",
    "            cv2.putText(aOutImage, \"IoU: {:.4f}\".format(aIOU), (10, 20), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)    \n",
    "            cv2.imwrite(os.path.join(ab_path, aBbox_file), aOutImage)\n",
    "\n",
    "            tOutImage = np.copy(tImg)\n",
    "            for c_b in tBBox_coord:\n",
    "                cv2.rectangle(tOutImage, (c_b[0], c_b[1]), (c_b[2], c_b[3]), (255,0,0), 2)\n",
    "            for g_b in groundtruth_bbox_set:\n",
    "                cv2.rectangle(tOutImage, (g_b[0], g_b[1]), (g_b[2], g_b[3]), (0,255,0), 2)\n",
    "\n",
    "            tb_path      = tCRM_bbox_output_path + str(Th_set[idx]) + '/'\n",
    "            if not os.path.exists(tb_path):\n",
    "                os.makedirs(tb_path)              \n",
    "            cv2.putText(tOutImage, \"IoU: {:.4f}\".format(tIOU), (10, 20), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)    \n",
    "            cv2.imwrite(os.path.join(tb_path, tBbox_file), tOutImage)\n",
    "\n",
    "        \n",
    "            b  = serializeCRM(fname, aBBox_coord.tolist(), aBBox_score.tolist())\n",
    "            tb = serializeCRM(fname, tBBox_coord.tolist(), tBBox_score.tolist())\n",
    "            g  = serializeGT(fname, groundtruth_bbox_set.tolist())           \n",
    "            \n",
    "            if len(bb_data[idx]) > 0:\n",
    "                bb_data[idx].update(b)\n",
    "            else:\n",
    "                bb_data[idx] = dict(b)           # create dictionary\n",
    "\n",
    "            if len(tb_data[idx]) > 0:\n",
    "                tb_data[idx].update(tb)\n",
    "            else:\n",
    "                tb_data[idx] = dict(tb)           # create dictionary\n",
    "\n",
    "            if len(gt_data[idx]) > 0:\n",
    "                gt_data[idx].update(g)\n",
    "            else:\n",
    "                gt_data[idx] = dict(g)           # create dictionary\n",
    "     \n",
    "        f1.write(eval_result + '\\n')\n",
    "\n",
    "        i += 1\n",
    "        print (i)\n",
    "\n",
    "    for Th in range(len(Th_set)):\n",
    "        with open(os.path.join(Visualization_path, 'Ensemble5_BBox_predicted_' + str(Th_set[Th]) + '.json'), 'w') as outfile:\n",
    "            json.dump(bb_data[Th], outfile)\n",
    "        with open(os.path.join(Visualization_path, 'Ensemble5_tBBox_predicted_' + str(Th_set[Th]) + '.json'), 'w') as outfile:\n",
    "            json.dump(tb_data[Th], outfile)\n",
    "        with open(os.path.join(Visualization_path, 'Ensemble5_BBox_groundtruth_' + str(Th_set[Th]) + '.json'), 'w') as outfile:\n",
    "            json.dump(gt_data[Th], outfile)\n",
    "\n",
    "\n",
    "    avg_aIOU /= float(i-err_cnt)\n",
    "    avg_tIOU /= float(i-err_cnt)\n",
    "    f1.write(\"\\n\\nTotal Errors: {:d}\\n\".format(err_cnt))\n",
    "    f1.write(\"No. of testing images (having groundtruth bbox): {:d}\\n\".format(i))\n",
    "    f1.write(\"Accuracy: {:.5f}\\n\".format((float(i-err_cnt)/float(i))*100.))\n",
    "\n",
    "    for ix in range(len(avg_aIOU)):\n",
    "        f1.write(\"avrage aIOU_\" + str(Th_set[ix]) + \": {:.4f}  |\".format(avg_aIOU[ix]))                                            \n",
    "        f1.write(\"avrage tIOU_\" + str(Th_set[ix]) + \": {:.4f}\\n\".format(avg_tIOU[ix]))                                            \n",
    "    f1.close()\n",
    "     \n",
    "    print('done')\n",
    "\n",
    "except Exception as e:\n",
    "    print (str(e))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The computed classification result, bounding boxes for different CRM thresholds, the JSON converted files are stored in the results folder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#computing mean average precision using the JSON files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "\n",
    "from __future__ import absolute_import, division, print_function\n",
    "\n",
    "from copy import deepcopy\n",
    "import json\n",
    "import glob\n",
    "import os\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_style('white')\n",
    "sns.set_context('poster')\n",
    "\n",
    "COLORS = [\n",
    "    '#1f77b4', '#aec7e8', '#ff7f0e', '#ffbb78', '#2ca02c',\n",
    "    '#98df8a', '#d62728', '#ff9896', '#9467bd', '#c5b0d5',\n",
    "    '#8c564b', '#c49c94', '#e377c2', '#f7b6d2', '#7f7f7f',\n",
    "    '#c7c7c7', '#bcbd22', '#dbdb8d', '#17becf', '#9edae5']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate individual IOUs using the ppredicted and ground truth BB for the CRM threshold of 0.1\n",
    "#that gave the best IOU values\n",
    "\n",
    "def calc_iou_individual(pred_box, gt_box):\n",
    "    \"\"\"Calculate IoU of single predicted and ground truth box\n",
    "\n",
    "    Args:\n",
    "        pred_box (list of floats): location of predicted object as [xmin, ymin, xmax, ymax]\n",
    "        gt_box (list of floats): location of ground truth object as [xmin, ymin, xmax, ymax]\n",
    "\n",
    "    Returns:\n",
    "        float: value of the IoU for the two boxes.\n",
    "\n",
    "    Raises:\n",
    "        AssertionError: if the box is obviously malformed\n",
    "    \"\"\"\n",
    "    x1_t, y1_t, x2_t, y2_t = gt_box\n",
    "    x1_p, y1_p, x2_p, y2_p = pred_box\n",
    "\n",
    "    if (x1_p > x2_p) or (y1_p > y2_p):\n",
    "        raise AssertionError(\n",
    "            \"Prediction box is malformed? pred box: {}\".format(pred_box))\n",
    "    if (x1_t > x2_t) or (y1_t > y2_t):\n",
    "        raise AssertionError(\n",
    "            \"Ground Truth box is malformed? true box: {}\".format(gt_box))\n",
    "\n",
    "    if (x2_t < x1_p or x2_p < x1_t or y2_t < y1_p or y2_p < y1_t):\n",
    "        return 0.0\n",
    "\n",
    "    far_x = np.min([x2_t, x2_p])\n",
    "    near_x = np.max([x1_t, x1_p])\n",
    "    far_y = np.min([y2_t, y2_p])\n",
    "    near_y = np.max([y1_t, y1_p])\n",
    "\n",
    "    inter_area = (far_x - near_x + 1) * (far_y - near_y + 1)\n",
    "    true_box_area = (x2_t - x1_t + 1) * (y2_t - y1_t + 1)\n",
    "    pred_box_area = (x2_p - x1_p + 1) * (y2_p - y1_p + 1)\n",
    "    iou = inter_area / (true_box_area + pred_box_area - inter_area)\n",
    "    return iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get single image results\n",
    "def get_single_image_results(gt_boxes, pred_boxes, iou_thr):\n",
    "    \"\"\"Calculates number of true_pos, false_pos, false_neg from single batch of boxes.\n",
    "\n",
    "    Args:\n",
    "        gt_boxes (list of list of floats): list of locations of ground truth objects as [xmin, ymin, xmax, ymax]\n",
    "        pred_boxes (dict): dict of dicts of 'boxes' (formatted like `gt_boxes`) and 'scores'\n",
    "        iou_thr (float): value of IoU to consider as threshold for a true prediction.\n",
    "\n",
    "    Returns:\n",
    "        dict: true positives (int), false positives (int), false negatives (int)\n",
    "    \"\"\"\n",
    "\n",
    "    all_pred_indices = range(len(pred_boxes))\n",
    "    all_gt_indices = range(len(gt_boxes))\n",
    "    if len(all_pred_indices) == 0:\n",
    "        tp = 0\n",
    "        fp = 0\n",
    "        fn = len(gt_boxes)\n",
    "        return {'true_pos': tp, 'false_pos': fp, 'false_neg': fn}\n",
    "    if len(all_gt_indices) == 0:\n",
    "        tp = 0\n",
    "        fp = len(pred_boxes)\n",
    "        fn = 0\n",
    "        return {'true_pos': tp, 'false_pos': fp, 'false_neg': fn}\n",
    "\n",
    "    gt_idx_thr = []\n",
    "    pred_idx_thr = []\n",
    "    ious = []\n",
    "    for ipb, pred_box in enumerate(pred_boxes):\n",
    "        for igb, gt_box in enumerate(gt_boxes):\n",
    "            iou = calc_iou_individual(pred_box, gt_box)\n",
    "            if iou > iou_thr:\n",
    "                gt_idx_thr.append(igb)\n",
    "                pred_idx_thr.append(ipb)\n",
    "                ious.append(iou)\n",
    "\n",
    "    args_desc = np.argsort(ious)[::-1]\n",
    "    if len(args_desc) == 0:\n",
    "        # No matches\n",
    "        tp = 0\n",
    "        fp = len(pred_boxes)\n",
    "        fn = len(gt_boxes)\n",
    "    else:\n",
    "        gt_match_idx    = []\n",
    "        pred_match_idx  = []\n",
    "        for idx in args_desc:\n",
    "            gt_idx = gt_idx_thr[idx]\n",
    "            pr_idx = pred_idx_thr[idx]\n",
    "            # If the boxes are unmatched, add them to matches\n",
    "            if (gt_idx not in gt_match_idx) and (pr_idx not in pred_match_idx):\n",
    "                gt_match_idx.append(gt_idx)\n",
    "                pred_match_idx.append(pr_idx)\n",
    "        tp = len(gt_match_idx)\n",
    "        fp = len(pred_boxes) - len(pred_match_idx)\n",
    "        fn = len(gt_boxes)   - len(gt_match_idx)\n",
    "\n",
    "    return {'true_pos': tp, 'false_pos': fp, 'false_neg': fn}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate precision recall curves from the data\n",
    "def calc_precision_recall(img_results):\n",
    "    \"\"\"Calculates precision and recall from the set of images\n",
    "\n",
    "    Args:\n",
    "        img_results (dict): dictionary formatted like:\n",
    "            {\n",
    "                'img_id1': {'true_pos': int, 'false_pos': int, 'false_neg': int},\n",
    "                'img_id2': ...\n",
    "                ...\n",
    "            }\n",
    "\n",
    "    Returns:\n",
    "        tuple: of floats of (precision, recall)\n",
    "    \"\"\"\n",
    "    true_pos = 0; false_pos = 0; false_neg = 0\n",
    "    for _, res in img_results.items():\n",
    "        true_pos  += res['true_pos']\n",
    "        false_pos += res['false_pos']\n",
    "        false_neg += res['false_neg']\n",
    "\n",
    "    try:\n",
    "        precision = true_pos/(true_pos + false_pos)\n",
    "    except ZeroDivisionError:\n",
    "        precision = 0.0\n",
    "    try:\n",
    "        recall = true_pos/(true_pos + false_neg)\n",
    "    except ZeroDivisionError:\n",
    "        recall = 0.0\n",
    "\n",
    "    return (precision, recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compute model scores map\n",
    "def get_model_scores_map(pred_boxes):\n",
    "    \"\"\"Creates a dictionary of from model_scores to image ids.\n",
    "\n",
    "    Args:\n",
    "        pred_boxes (dict): dict of dicts of 'boxes' and 'scores'\n",
    "\n",
    "    Returns:\n",
    "        dict: keys are model_scores and values are image ids (usually filenames)\n",
    "\n",
    "    \"\"\"\n",
    "    model_scores_map = {}\n",
    "    for img_id, val in pred_boxes.items():\n",
    "        for score in val['scores']:\n",
    "            if score not in model_scores_map.keys():\n",
    "                model_scores_map[score] = [img_id]\n",
    "            else:\n",
    "                model_scores_map[score].append(img_id)\n",
    "    return model_scores_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compute average precision values\n",
    "def get_avg_precision_at_iou(gt_boxes, pred_boxes, iou_thr=0.5):\n",
    "    \"\"\"Calculates average precision at given IoU threshold.\n",
    "\n",
    "    Args:\n",
    "        gt_boxes (list of list of floats): list of locations of ground truth objects as [xmin, ymin, xmax, ymax]\n",
    "        pred_boxes (list of list of floats): list of locations of predicted objects as [xmin, ymin, xmax, ymax]\n",
    "        iou_thr (float): value of IoU to consider as threshold for a true prediction.\n",
    "\n",
    "    Returns:\n",
    "        dict: avg precision as well as summary info about the PR curve\n",
    "\n",
    "        Keys:\n",
    "            'avg_prec' (float): average precision for this IoU threshold\n",
    "            'precisions' (list of floats): precision value for the given model_threshold\n",
    "            'recall' (list of floats): recall value for given model_threshold\n",
    "            'models_thrs' (list of floats): model threshold value that precision and recall were computed for.\n",
    "    \"\"\"\n",
    "    model_scores_map = get_model_scores_map(pred_boxes)\n",
    "    sorted_model_scores = sorted(model_scores_map.keys())\n",
    "\n",
    "    # Sort the predicted boxes in descending order (lowest scoring boxes first):\n",
    "    for img_id in pred_boxes.keys():\n",
    "        arg_sort = np.argsort(pred_boxes[img_id]['scores'])\n",
    "        pred_boxes[img_id]['scores'] = np.array(pred_boxes[img_id]['scores'])[arg_sort].tolist()\n",
    "        pred_boxes[img_id]['boxes']  = np.array(pred_boxes[img_id]['boxes'])[arg_sort].tolist()\n",
    "\n",
    "    pred_boxes_pruned = deepcopy(pred_boxes)\n",
    "\n",
    "    precisions  = []\n",
    "    recalls     = []\n",
    "    model_thrs  = []\n",
    "    img_results = {}\n",
    "    # Loop over model score thresholds and calculate precision, recall\n",
    "    for ithr, model_score_thr in enumerate(sorted_model_scores[:-1]):\n",
    "        # On first iteration, define img_results for the first time:\n",
    "        img_ids = gt_boxes.keys() if ithr == 0 else model_scores_map[model_score_thr]\n",
    "        for img_id in img_ids:\n",
    "            gt_boxes_img = gt_boxes[img_id]\n",
    "            box_scores = pred_boxes_pruned[img_id]['scores']\n",
    "            start_idx = 0\n",
    "            for score in box_scores:\n",
    "                if score <= model_score_thr:\n",
    "                    pred_boxes_pruned[img_id]\n",
    "                    start_idx += 1\n",
    "                else:\n",
    "                    break\n",
    "\n",
    "            # Remove boxes, scores of lower than threshold scores:\n",
    "            pred_boxes_pruned[img_id]['scores'] = pred_boxes_pruned[img_id]['scores'][start_idx:]\n",
    "            pred_boxes_pruned[img_id]['boxes']  = pred_boxes_pruned[img_id]['boxes'][start_idx:]\n",
    "\n",
    "            # Recalculate image results for this image\n",
    "            img_results[img_id] = get_single_image_results(gt_boxes_img, pred_boxes_pruned[img_id]['boxes'], iou_thr)\n",
    "\n",
    "        prec, rec = calc_precision_recall(img_results)\n",
    "        precisions.append(prec)\n",
    "        recalls.append(rec)\n",
    "        model_thrs.append(model_score_thr)\n",
    "\n",
    "    precisions = np.array(precisions)\n",
    "    recalls = np.array(recalls)\n",
    "    prec_at_rec = []\n",
    "    for recall_level in np.linspace(0.0, 1.0, 11):\n",
    "        try:\n",
    "            args = np.argwhere(recalls >= recall_level).flatten()\n",
    "            prec = max(precisions[args])\n",
    "        except ValueError:\n",
    "            prec = 0.0\n",
    "        prec_at_rec.append(prec)\n",
    "    avg_prec = np.mean(prec_at_rec)\n",
    "\n",
    "    return {\n",
    "        'avg_prec': avg_prec,\n",
    "        'precisions': precisions,\n",
    "        'recalls': recalls,\n",
    "        'model_thrs': model_thrs}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot precision recall curve\n",
    "def plot_pr_curve(precisions, recalls, category='Person', label=None, color=None, ax=None):    \n",
    " \n",
    "    if ax is None:\n",
    "        plt.figure(figsize=(10,8))\n",
    "        ax = plt.gca()\n",
    "\n",
    "    if color is None:\n",
    "        color = COLORS[0]\n",
    "\n",
    "    ax.scatter(recalls, precisions, label=label, s=5, color=color)\n",
    "    ax.set_xlabel('recall', fontsize='medium')\n",
    "    ax.set_ylabel('precision', fontsize='medium')\n",
    "    ax.set_title('Precision-Recall curve\\n')\n",
    "    ax.set_xlim([0.0,1.15])\n",
    "    ax.set_ylim([0.0,1.15])\n",
    "    ax.tick_params(axis='x',which='major',direction='out',length=8,pad=-5,labelsize=20)\n",
    "    ax.tick_params(axis='y',which='major',direction='out',length=8,pad=-5,labelsize=20)\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#give the location of the JSON files for the ground truth and predicted bounding boxes\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    bBox_groundtruth_File = 'C:/Users/rajaramans2/codes/omsakthi_ensemble_visualization_kaggle/visualization/Ensemble5_BBox_groundtruth_0.1.json'\n",
    "    bBox_prediction_File = 'C:/Users/rajaramans2/codes/omsakthi_ensemble_visualization_kaggle/visualization/Ensemble5_tBBox_predicted_0.1.json'\n",
    "    print(\"\\n ****** Calculating mAP:  \" + bBox_prediction_File + \"****** \\n\")\n",
    "    \n",
    "    with open(bBox_groundtruth_File) as infile:\n",
    "        gt_boxes = json.load(infile)\n",
    "\n",
    "    with open(bBox_prediction_File) as infile:\n",
    "        pred_boxes = json.load(infile)\n",
    "\n",
    "    # Runs it for one IoU threshold\n",
    "    iou_thr = 0.2\n",
    "    start_time = time.time()\n",
    "    data = get_avg_precision_at_iou(gt_boxes, pred_boxes, iou_thr=iou_thr)\n",
    "    end_time = time.time()\n",
    "    print('Single IoU calculation took {:.4f} secs'.format(end_time - start_time))\n",
    "    print('avg precision: {:.4f}'.format(data['avg_prec']))\n",
    "\n",
    "    start_time = time.time()\n",
    "    ax = None\n",
    "    avg_precs = []\n",
    "    iou_thrs = []\n",
    "    for idx, iou_thr in enumerate(np.linspace(0.1, 0.6, 10)):          #(0.5, 0.95, 10)\n",
    "        data = get_avg_precision_at_iou(gt_boxes, pred_boxes, iou_thr=iou_thr)\n",
    "        avg_precs.append(data['avg_prec'])\n",
    "        iou_thrs.append(iou_thr)\n",
    "\n",
    "        precisions = data['precisions']\n",
    "        recalls = data['recalls']\n",
    "        ax = plot_pr_curve(\n",
    "            precisions, recalls, label='{:.2f}'.format(iou_thr), color=COLORS[idx*2], ax=ax)\n",
    "\n",
    "    # prettify for printing:\n",
    "    avg_precs = [float('{:.4f}'.format(ap)) for ap in avg_precs]\n",
    "    iou_thrs = [float('{:.4f}'.format(thr)) for thr in iou_thrs]\n",
    "    print('mAP: {:.2f}'.format(100*np.mean(avg_precs)))\n",
    "    print('avg precs: ', avg_precs)\n",
    "    print('iou_thrs:  ', iou_thrs)\n",
    "    legend = plt.legend(loc='upper right', title='IOU Thr', fontsize='x-small', frameon=True)\n",
    "    legend.get_title().set_fontsize('20')\n",
    "    for xval in np.linspace(0.0, 1.0, 11):\n",
    "        plt.vlines(xval, 0.0, 1.1, color='gray', alpha=0.3, linestyles='dashed')\n",
    "    end_time = time.time()\n",
    "    print('\\nPlotting and calculating mAP takes {:.4f} secs'.format(end_time - start_time))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
